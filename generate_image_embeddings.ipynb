{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd3fa0e",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba8d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings import get_embeddings_df\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5558d8",
   "metadata": {},
   "source": [
    "## Embeddings Generation\n",
    "\n",
    "* **Batch Size:** Images per batch to convert to embeddings (Adjust depending on your memory)\n",
    "\n",
    "* **Path:** Path to the images\n",
    "\n",
    "* **Output Directory:** Directory to save the embeddings\n",
    "\n",
    "* **Backbone:** Select a backbone from the list of possible backbones:\n",
    "    * 'dinov2_small'\n",
    "    * 'dinov2_base'\n",
    "    * 'dinov2_large'\n",
    "    * 'dinov2_giant'\n",
    "    * 'sam_base'\n",
    "    * 'sam_large'\n",
    "    * 'sam_huge'\n",
    "    * 'clip_base',\n",
    "    * 'clip_large',\n",
    "    * 'convnextv2_tiny'\n",
    "    * 'convnextv2_base'\n",
    "    * 'convnextv2_large'\n",
    "    * 'convnext_tiny'\n",
    "    * 'convnext_small'\n",
    "    * 'convnext_base'\n",
    "    * 'convnext_large'\n",
    "    * 'swin_tiny'\n",
    "    * 'swin_small'\n",
    "    * 'swin_base'\n",
    "    * 'vit_base'\n",
    "    * 'vit_large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea11f4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dinov2_small',\n",
       " 'dinov2_base',\n",
       " 'dinov2_large',\n",
       " 'dinov2_giant',\n",
       " 'clip_base',\n",
       " 'clip_large',\n",
       " 'sam_base',\n",
       " 'sam_large',\n",
       " 'sam_huge',\n",
       " 'convnextv2_tiny',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_large',\n",
       " 'convnext_tiny',\n",
       " 'convnext_small',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'swin_tiny',\n",
       " 'swin_small',\n",
       " 'swin_base',\n",
       " 'vit_base',\n",
       " 'vit_large',\n",
       " 'retfound']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Foundational Models\n",
    "dino_backbone = ['dinov2_small', 'dinov2_base', 'dinov2_large', 'dinov2_giant']\n",
    "\n",
    "sam_backbone = ['sam_base', 'sam_large', 'sam_huge']\n",
    "\n",
    "clip_backbone = ['clip_base', 'clip_large']\n",
    "\n",
    "# ImageNet:\n",
    "\n",
    "### Convnext\n",
    "convnext_backbone = ['convnextv2_tiny', 'convnextv2_base', 'convnextv2_large'] + ['convnext_tiny', 'convnext_small', 'convnext_base', 'convnext_large']\n",
    "\n",
    "### Swin Transformer\n",
    "swin_transformer_backbone = ['swin_tiny', 'swin_small', 'swin_base']\n",
    "\n",
    "### ViT\n",
    "vit_backbone = ['vit_base', 'vit_large']\n",
    "\n",
    "### RetFound\n",
    "retfound_backbone = ['retfound']\n",
    "\n",
    "backbones = dino_backbone + clip_backbone + sam_backbone + convnext_backbone + swin_transformer_backbone + vit_backbone + retfound_backbone\n",
    "\n",
    "backbones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14932b4",
   "metadata": {},
   "source": [
    "### Satellite Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23687d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31493685",
   "metadata": {},
   "source": [
    "### BRSET Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca8b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################  dinov2_large  ##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/datascience/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch number: 10\n",
      "Processed batch number: 20\n",
      "Processed batch number: 30\n",
      "Processed batch number: 40\n",
      "Processed batch number: 50\n",
      "Processed batch number: 60\n",
      "Processed batch number: 70\n",
      "Processed batch number: 80\n",
      "Processed batch number: 90\n",
      "Processed batch number: 100\n",
      "Processed batch number: 110\n",
      "Processed batch number: 120\n",
      "Processed batch number: 130\n",
      "Processed batch number: 140\n",
      "Processed batch number: 150\n",
      "Processed batch number: 160\n",
      "Processed batch number: 170\n",
      "Processed batch number: 180\n",
      "Processed batch number: 190\n",
      "Processed batch number: 200\n",
      "Processed batch number: 210\n",
      "Processed batch number: 220\n",
      "Processed batch number: 230\n",
      "Processed batch number: 240\n",
      "Processed batch number: 250\n",
      "Processed batch number: 260\n",
      "Processed batch number: 270\n",
      "Processed batch number: 280\n",
      "Processed batch number: 290\n",
      "Processed batch number: 300\n",
      "Processed batch number: 310\n",
      "Processed batch number: 320\n",
      "Processed batch number: 330\n",
      "Processed batch number: 340\n",
      "Processed batch number: 350\n",
      "Processed batch number: 360\n",
      "Processed batch number: 370\n",
      "Processed batch number: 380\n",
      "Processed batch number: 390\n",
      "Processed batch number: 400\n",
      "Processed batch number: 410\n",
      "Processed batch number: 420\n",
      "Processed batch number: 430\n",
      "Processed batch number: 440\n",
      "Processed batch number: 450\n",
      "Processed batch number: 460\n",
      "Processed batch number: 470\n",
      "Processed batch number: 480\n",
      "Processed batch number: 490\n",
      "Processed batch number: 500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "path = '/home/datascience/Retina/datasets/BRSET/images/'\n",
    "backbone = 'dinov2_large'\n",
    "out_dir = 'Embeddings'\n",
    "\n",
    "get_embeddings_df(batch_size=batch_size, path=path, backbone=backbone, directory=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f48d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_fusion_v0_0_1]",
   "language": "python",
   "name": "conda-env-data_fusion_v0_0_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
